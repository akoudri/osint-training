#!/usr/bin/env python3
"""
Twitter Network Crawler pour analyse Maltego
Explore les relations sociales sur Twitter/X en profondeur
Export CSV : qui parle avec qui et quand
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import random
import csv
import os
import urllib.parse
from datetime import datetime
from collections import deque

# ========== CONFIGURATION ==========

# Compte de dÃ©part pour l'analyse
COMPTE_INITIAL = "wh1t3h4ts"  # Sans le @

# Profondeur de l'exploration
MAX_DEPTH = 2  # 0 = compte initial, 1 = relations directes, 2 = relations des relations

# Nombre maximum de relations Ã  explorer par nÅ“ud
MAX_RELATIONS_PAR_NOEUD = 10

# Navigateur
BROWSER = "chrome"  # "chrome" ou "firefox"
HEADLESS = False    # Mode sans interface graphique
USE_EXISTING_PROFILE = True

# DÃ©lais alÃ©atoires pour Ã©viter la dÃ©tection (en secondes)
DELAI_MIN_ENTRE_ACTIONS = 2
DELAI_MAX_ENTRE_ACTIONS = 5
DELAI_MIN_ENTRE_PROFILS = 5
DELAI_MAX_ENTRE_PROFILS = 10

# Fichiers de sortie
CSV_RELATIONS = "twitter_network_relations.csv"
CSV_NOEUDS = "twitter_network_noeuds.csv"
LOG_FILE = "twitter_network_log.txt"

# ========== CLASSES ==========

class TwitterNetworkCrawler:
    def __init__(self):
        self.driver = None
        self.wait = None
        self.relations = []  # Liste des relations (source, target, type, date)
        self.noeuds = {}     # Dictionnaire des nÅ“uds explorÃ©s
        self.queue = deque() # File d'attente pour l'exploration
        self.visited = set() # Comptes dÃ©jÃ  visitÃ©s

    def log(self, message):
        """Affiche et enregistre un message"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_msg = f"[{timestamp}] {message}"
        print(log_msg)
        with open(LOG_FILE, "a", encoding="utf-8") as f:
            f.write(log_msg + "\n")

    def delai_aleatoire(self, min_sec=None, max_sec=None):
        """Pause alÃ©atoire pour Ã©viter la dÃ©tection"""
        if min_sec is None:
            min_sec = DELAI_MIN_ENTRE_ACTIONS
        if max_sec is None:
            max_sec = DELAI_MAX_ENTRE_ACTIONS

        delai = random.uniform(min_sec, max_sec)
        time.sleep(delai)

    def init_browser(self):
        """Initialise le navigateur avec anti-dÃ©tection"""
        self.log("ğŸš€ Initialisation du navigateur...")

        if BROWSER.lower() == "chrome":
            from selenium.webdriver.chrome.options import Options as ChromeOptions
            from selenium.webdriver.chrome.service import Service as ChromeService
            import shutil

            options = ChromeOptions()
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option("useAutomationExtension", False)
            options.add_argument("--disable-blink-features=AutomationControlled")

            if HEADLESS:
                options.add_argument("--headless=new")

            options.add_argument("user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

            if USE_EXISTING_PROFILE:
                self.log("   ğŸ” Tentative d'utilisation du profil existant...")
                home = os.path.expanduser("~")
                chrome_path = f"{home}/.config/google-chrome"

                if os.path.exists(chrome_path):
                    import tempfile
                    import shutil as sh

                    original_profile = os.path.join(chrome_path, "Default")
                    if os.path.exists(original_profile):
                        temp_profile = tempfile.mkdtemp(prefix="selenium_twitter_")
                        self.log(f"   ğŸ“‚ Profil temporaire : {temp_profile}")

                        try:
                            important_files = ["Cookies", "Login Data", "Web Data", "Preferences"]
                            for file in important_files:
                                src = os.path.join(original_profile, file)
                                if os.path.exists(src):
                                    dst = os.path.join(temp_profile, file)
                                    sh.copy2(src, dst)

                            options.add_argument(f"--user-data-dir={temp_profile}")
                        except:
                            pass

            chromedriver_path = shutil.which("chromedriver")
            if not chromedriver_path:
                self.log("âŒ chromedriver non trouvÃ© !")
                return False

            service = ChromeService(chromedriver_path)
            self.driver = webdriver.Chrome(service=service, options=options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

        else:  # Firefox
            from selenium.webdriver.firefox.options import Options as FirefoxOptions
            from selenium.webdriver.firefox.service import Service as FirefoxService
            import shutil

            options = FirefoxOptions()
            if HEADLESS:
                options.add_argument("--headless")

            options.set_preference("dom.webdriver.enabled", False)
            options.set_preference("useAutomationExtension", False)

            geckodriver_path = shutil.which("geckodriver")
            if not geckodriver_path:
                self.log("âŒ geckodriver non trouvÃ© !")
                return False

            service = FirefoxService(geckodriver_path)
            self.driver = webdriver.Firefox(service=service, options=options)

        self.wait = WebDriverWait(self.driver, 10)
        self.log("   âœ… Navigateur initialisÃ©")
        return True

    def login_manuel(self):
        """Attend la connexion manuelle de l'utilisateur"""
        self.log("ğŸŒ Navigation vers Twitter/X...")
        self.driver.get("https://x.com/i/flow/login")

        self.log("\nğŸ›‘ ACTION REQUISE :")
        self.log("   1. Connectez-vous manuellement dans le navigateur")
        self.log("   2. RÃ©solvez les Ã©ventuels CAPTCHA")
        input("   ğŸ‘‰ Appuyez sur [ENTRÃ‰E] une fois connectÃ©...\n")

        self.log("âœ… Connexion confirmÃ©e")
        self.delai_aleatoire()

    def extraire_username_du_url(self, url):
        """Extrait le username depuis une URL Twitter"""
        try:
            parts = url.split('/')
            if 'x.com' in url or 'twitter.com' in url:
                for i, part in enumerate(parts):
                    if part in ['x.com', 'twitter.com'] and i + 1 < len(parts):
                        username = parts[i + 1]
                        if username and username not in ['home', 'explore', 'notifications', 'messages', 'i']:
                            return username.replace('@', '')
        except:
            pass
        return None

    def explorer_profil(self, username, depth):
        """Explore un profil et extrait ses interactions"""
        if username in self.visited:
            self.log(f"   â­ï¸  @{username} dÃ©jÃ  visitÃ©")
            return

        if depth > MAX_DEPTH:
            self.log(f"   ğŸ›‘ Profondeur max atteinte pour @{username}")
            return

        self.visited.add(username)
        self.log(f"\n{'  ' * depth}ğŸ“Š Exploration de @{username} (profondeur {depth})")

        # Visiter le profil
        profile_url = f"https://x.com/{username}"
        self.driver.get(profile_url)
        self.delai_aleatoire(DELAI_MIN_ENTRE_PROFILS, DELAI_MAX_ENTRE_PROFILS)

        # VÃ©rifier que le profil existe
        try:
            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, "article")))
        except TimeoutException:
            self.log(f"   âš ï¸  Profil @{username} inaccessible ou inexistant")
            return

        # Enregistrer le nÅ“ud
        self.noeuds[username] = {
            "username": username,
            "depth": depth,
            "timestamp": datetime.now().isoformat()
        }

        # Scroll et collecte des tweets
        self.log(f"{'  ' * depth}   ğŸ” Collecte des interactions...")
        interactions_count = 0
        scroll_count = 0
        max_scrolls = 3  # LimitÃ© pour Ã©viter trop de donnÃ©es

        tweets_vus = set()
        body = self.driver.find_element(By.TAG_NAME, "body")

        while scroll_count < max_scrolls and interactions_count < MAX_RELATIONS_PAR_NOEUD:
            # Extraire les tweets visibles
            articles = self.driver.find_elements(By.CSS_SELECTOR, 'article[data-testid="tweet"]')

            for article in articles:
                if interactions_count >= MAX_RELATIONS_PAR_NOEUD:
                    break

                try:
                    # Obtenir le texte du tweet pour dÃ©dupliquer
                    tweet_text = article.text[:100]
                    if tweet_text in tweets_vus:
                        continue
                    tweets_vus.add(tweet_text)

                    # Chercher les mentions ou rÃ©ponses
                    links = article.find_elements(By.CSS_SELECTOR, 'a[href*="/"]')

                    for link in links:
                        href = link.get_attribute('href')
                        if not href:
                            continue

                        target_user = self.extraire_username_du_url(href)

                        if target_user and target_user != username and target_user not in ['home', 'explore']:
                            # Type de relation
                            relation_type = "mention"
                            if "/status/" in href:
                                relation_type = "reply"

                            # Enregistrer la relation
                            relation = {
                                "source": username,
                                "target": target_user,
                                "type": relation_type,
                                "timestamp": datetime.now().isoformat(),
                                "depth": depth
                            }

                            self.relations.append(relation)
                            self.log(f"{'  ' * depth}      â†’ @{username} {relation_type} @{target_user}")

                            # Ajouter Ã  la file pour exploration future
                            if depth < MAX_DEPTH and target_user not in self.visited:
                                self.queue.append((target_user, depth + 1))

                            interactions_count += 1

                            if interactions_count >= MAX_RELATIONS_PAR_NOEUD:
                                break

                except Exception as e:
                    continue

            # Scroll
            body.send_keys(Keys.PAGE_DOWN)
            self.delai_aleatoire()
            scroll_count += 1

        self.log(f"{'  ' * depth}   âœ… {interactions_count} interactions trouvÃ©es")

    def explorer_reseau(self):
        """Explore le rÃ©seau social en largeur (BFS)"""
        self.log(f"\nğŸŒ DÃ©marrage de l'exploration depuis @{COMPTE_INITIAL}")
        self.log(f"   Profondeur max : {MAX_DEPTH}")
        self.log(f"   Relations max par nÅ“ud : {MAX_RELATIONS_PAR_NOEUD}\n")

        # Ajouter le compte initial
        self.queue.append((COMPTE_INITIAL, 0))

        while self.queue:
            username, depth = self.queue.popleft()
            self.explorer_profil(username, depth)

            # Pause entre chaque profil pour Ã©viter la dÃ©tection
            if self.queue:
                self.delai_aleatoire(DELAI_MIN_ENTRE_PROFILS, DELAI_MAX_ENTRE_PROFILS)

        self.log(f"\nâœ… Exploration terminÃ©e !")
        self.log(f"   NÅ“uds explorÃ©s : {len(self.noeuds)}")
        self.log(f"   Relations trouvÃ©es : {len(self.relations)}")

    def exporter_csv(self):
        """Exporte les donnÃ©es en CSV pour Maltego"""
        self.log("\nğŸ’¾ Export des donnÃ©es...")

        # CSV Relations (arÃªtes du graphe)
        with open(CSV_RELATIONS, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=['source', 'target', 'type', 'timestamp', 'depth'])
            writer.writeheader()
            writer.writerows(self.relations)

        self.log(f"   âœ… Relations exportÃ©es : {CSV_RELATIONS}")

        # CSV NÅ“uds
        with open(CSV_NOEUDS, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=['username', 'depth', 'timestamp'])
            writer.writeheader()
            for noeud in self.noeuds.values():
                writer.writerow(noeud)

        self.log(f"   âœ… NÅ“uds exportÃ©s : {CSV_NOEUDS}")

    def run(self):
        """ExÃ©cute le crawler complet"""
        try:
            if not self.init_browser():
                return

            self.login_manuel()
            self.explorer_reseau()
            self.exporter_csv()

            self.log("\nğŸ‰ TERMINÃ‰ ! Fichiers prÃªts pour Maltego :")
            self.log(f"   ğŸ“Š Relations : {CSV_RELATIONS}")
            self.log(f"   ğŸ“Š NÅ“uds : {CSV_NOEUDS}")

        except KeyboardInterrupt:
            self.log("\nâš ï¸  Interruption par l'utilisateur")
            if self.relations:
                self.log("   Sauvegarde des donnÃ©es collectÃ©es...")
                self.exporter_csv()

        except Exception as e:
            self.log(f"\nâŒ Erreur critique : {e}")
            import traceback
            traceback.print_exc()

        finally:
            if self.driver:
                self.log("\nğŸ”’ Fermeture du navigateur dans 5 secondes...")
                time.sleep(5)
                self.driver.quit()


# ========== EXÃ‰CUTION ==========

if __name__ == "__main__":
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘           TWITTER NETWORK CRAWLER - Analyse pour Maltego                    â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

    print(f"ğŸ“Š Configuration :")
    print(f"   Compte initial : @{COMPTE_INITIAL}")
    print(f"   Profondeur : {MAX_DEPTH}")
    print(f"   Relations max/nÅ“ud : {MAX_RELATIONS_PAR_NOEUD}")
    print(f"   Navigateur : {BROWSER.upper()}")
    print(f"   DÃ©lais anti-dÃ©tection : {DELAI_MIN_ENTRE_ACTIONS}-{DELAI_MAX_ENTRE_ACTIONS}s\n")

    confirmation = input("Voulez-vous continuer ? (o/N) : ")
    if confirmation.lower() not in ['o', 'y', 'oui', 'yes']:
        print("âŒ AnnulÃ©")
        exit(0)

    crawler = TwitterNetworkCrawler()
    crawler.run()
